{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "349b9d11-f4f0-4437-9178-c428c9d4c5ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook creates the staging table and the silver table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51b1b29e-84ed-46b2-af64-c4b8a53bb81f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Read file from adls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff0f27f6-1196-467d-b16b-a9e2a0275138",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit, current_date, date_sub\n",
    "from delta.tables import DeltaTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28f3bfaa-8ee9-4b04-9d25-bb2fb11547cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format('parquet').load('abfss://bronze@storagegeneral00001.dfs.core.windows.net/volumes/raw_covid/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c896329d-69e1-4444-adb4-76b9bb50b0dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = df.select(\n",
    "    col('Date_reported').cast('date'),\n",
    "    col('Country_code'),\n",
    "    col('Country'),\n",
    "    col('WHO_Region'),\n",
    "    col('New_cases').cast('int'),\n",
    "    col('Cumulative_cases').cast('bigint'),\n",
    "    col('New_deaths').cast('int'),\n",
    "    col('Cumulative_deaths').cast('bigint')\n",
    "    ).withColumn('Last_update', current_date())\n",
    "\n",
    "\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98ad6b3d-8eef-42f7-931f-79bd818c7a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if not spark.catalog.tableExists('cat_covid.silver.covid'):\n",
    "    df = df.na.drop(subset=['Country', 'Date_reported'])\n",
    "    df = df.na.fill(0, subset=['New_cases', 'Cumulative_cases', 'New_deaths', 'Cumulative_deaths'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e2ee51c-091e-4897-b5c1-f656db5dbc41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Create staging table for the last 30 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "482256e3-73c0-402f-8109-773c806b7664",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_staging = df.filter(col('Date_reported') >= date_sub(current_date(), 30))\n",
    "\n",
    "df_staging = df_staging.na.drop(subset=['Country'])\n",
    "df_staging = df_staging.fillna(0, subset=['New_cases', 'Cumulative_cases', 'New_deaths', 'Cumulative_deaths'])\n",
    "\n",
    "df_staging.write.mode('overwrite').format('delta').option('overwriteSchema', True).saveAsTable('cat_covid.bronze.stagingcovid')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a773e905-9b29-4e4f-ade1-628e460dfee0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Incremental loading\n",
    "The incremental loading will consider the last 30 days in order to update the registers and insert the new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d45e16d2-9bfd-409f-9053-4e3477f15452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if spark.catalog.tableExists('cat_covid.silver.covid'):\n",
    "    target = DeltaTable.forName(spark, 'cat_covid.silver.covid')\n",
    "    target.alias('t').merge(\n",
    "        df_staging.alias('s'),\n",
    "        't.Date_reported = s.Date_reported AND t.Country_code = s.Country_code'\n",
    "        ).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "else:\n",
    "    df.write.mode('overwrite').format('delta').option('overwriteSchema', True).saveAsTable('cat_covid.silver.covid')\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_covid_nb",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
